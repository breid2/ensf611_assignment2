{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: 262200\n",
      "X type <class 'pandas.core.frame.DataFrame'>\n",
      "y size: 4600\n",
      "y type <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_spam\n",
    "# TO DO: Print size and type of X and y\n",
    "X, y = load_spam()\n",
    "print(\"X size:\", X.size)\n",
    "print(\"X type\", type(X))\n",
    "print(\"y size:\", y.size)\n",
    "print(\"y type\", type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "X.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_large, X_small, y_large, y_small = train_test_split(X, y, test_size=0.05, stratify=y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Data Size  Training Accuracy  Validation Accuracy\n",
      "0  (4600, 57)           0.928116             0.938261\n",
      "1   (4600, 2)           0.608406             0.613043\n",
      "2   (230, 57)           0.936047             0.862069\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "results = pd.DataFrame(columns=['Data Size', 'Training Accuracy', 'Validation Accuracy'])\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dataX = [X, X.iloc[:, :2], X_small]\n",
    "datay = [y, y, y_small]\n",
    "for i in range(3):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(dataX[i], datay[i], random_state = 0)\n",
    "    logreg = LogisticRegression(max_iter=2000).fit(X_train, y_train)\n",
    "    train_score = accuracy_score(y_train, logreg.predict(X_train))\n",
    "    val_score = accuracy_score(y_val, logreg.predict(X_val))\n",
    "    results.loc[len(results.index)] = [dataX[i].shape, train_score, val_score]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "The training and validation accuracies increase when a larger dataset with more columns are used. The highest validation accuracy was with the full dataset (X), and close behind was the 5% (X_small). The result with using the first two columns of X was significantly worse due to the omission of the other 55 columns. Even though the number of data points in the X_small was similar to the two columns of X, those two columns were clearly not sufficient in creating an accurate model. \n",
    "\n",
    "In this case, a false positive is a real email that was marked as spam, and a false negative was a spam email marked as real. The worse case is a false positive as it means a user might miss an important email, whereas a false negative is a minor inconvenience for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code? \n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "1. I sourced it from the notes, online searches, and chatGPT\n",
    "1. I completed all the steps in order\n",
    "1. I asked chatGPT: \"how to select the first two columns of a pandas dataframe in python\", I did need to slightly alter the code as it gave me a full example when I just wanted the iloc syntax, and it used the default dataframe 'df'\n",
    "1. I was initially confused with the train_test_split of 5%, since I wasn't sure if we were supposed to use it again to make our model. Reading through the notes again helped. Also on my first attempt the dataset would not load and I had to reset my conda environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: 8240\n",
      "X type <class 'pandas.core.frame.DataFrame'>\n",
      "y size: 1030\n",
      "y type <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete()\n",
    "print(\"X size:\", X.size)\n",
    "print(\"X type\", type(X))\n",
    "print(\"y size:\", y.size)\n",
    "print(\"y type\", type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cement    0\n",
       "slag      0\n",
       "ash       0\n",
       "water     0\n",
       "splast    0\n",
       "coarse    0\n",
       "fine      0\n",
       "age       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mse score: 111.36\n",
      "Validation mse score: 95.90\n",
      "Training r2 score: 0.61\n",
      "Validation r2 score: 0.62\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "train_mse = mean_squared_error(y_train, lr.predict(X_train))\n",
    "train_r2 = r2_score(y_train, lr.predict(X_train))\n",
    "val_mse = mean_squared_error(y_val, lr.predict(X_val))\n",
    "val_r2 = r2_score(y_val, lr.predict(X_val))\n",
    "print(\"Training mse score: {:.2f}\".format(train_mse))\n",
    "print(\"Validation mse score: {:.2f}\".format(val_mse))\n",
    "print(\"Training r2 score: {:.2f}\".format(train_r2))\n",
    "print(\"Validation r2 score: {:.2f}\".format(val_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Training Accuracy  Validation Accuracy\n",
      "MSE         111.358439            95.904136\n",
      "R2            0.610823             0.623414\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "results = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'])\n",
    "results.loc['MSE'] = [train_mse, val_mse]\n",
    "results.loc['R2'] = [train_r2, val_r2]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "No it didn't as the training and validation scores are both quite low for r2 and high for MSE. This dataset likely doesn't follow a linear relationship for the different attributes. A more complex model is required to properly fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "1. I sourced my code from the lectures and class examples, as well as some google searches for MSE and R2 methods\n",
    "1. I completed the steps in the order provided\n",
    "1. I did not use AI for this part of the assignment\n",
    "1. I was confused in Step 3 as it asks to import a linear model, but then instantiate a logistic regression, but I assume that was maybe just a typo. Once I got past that it was all good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "Based on the results the linear model is not sufficient in predicting the outcome. The model is likely underfitting the data. There are not many features in this dataset, so the linear model stuggles to predict the values. It is possible that some regularization could help in this scenario. The r2 score of 0.6 indicates that the model does not fit the data well as the score should be closer to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "I liked implementing a different kind of model as it is important to see how different models predict on different datasets. But I did find it difficult to do the r2 and MSE functions initially as we had not yet seen an example in class. Once I went on the scikitlearn website and saw the import statements it went well from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Training Accuracy MSE</th>\n",
       "      <th>Validation Accuracy MSE</th>\n",
       "      <th>Training Accuracy R^2</th>\n",
       "      <th>Validation Accuracy R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ridge1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>111.358439</td>\n",
       "      <td>95.904136</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>111.358439</td>\n",
       "      <td>95.904135</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>111.358439</td>\n",
       "      <td>95.904126</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>111.358439</td>\n",
       "      <td>95.904035</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge5</th>\n",
       "      <td>10.000</td>\n",
       "      <td>111.358440</td>\n",
       "      <td>95.903131</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge6</th>\n",
       "      <td>100.000</td>\n",
       "      <td>111.358548</td>\n",
       "      <td>95.894268</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>111.358439</td>\n",
       "      <td>95.903755</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>111.358445</td>\n",
       "      <td>95.900332</td>\n",
       "      <td>0.610823</td>\n",
       "      <td>0.623429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>111.359051</td>\n",
       "      <td>95.866646</td>\n",
       "      <td>0.610821</td>\n",
       "      <td>0.623562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>111.419648</td>\n",
       "      <td>95.584678</td>\n",
       "      <td>0.610609</td>\n",
       "      <td>0.624669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso5</th>\n",
       "      <td>10.000</td>\n",
       "      <td>113.220780</td>\n",
       "      <td>95.048607</td>\n",
       "      <td>0.604314</td>\n",
       "      <td>0.626774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso6</th>\n",
       "      <td>100.000</td>\n",
       "      <td>152.346820</td>\n",
       "      <td>125.446062</td>\n",
       "      <td>0.467576</td>\n",
       "      <td>0.507413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alpha  Training Accuracy MSE  Validation Accuracy MSE  \\\n",
       "ridge1    0.001             111.358439                95.904136   \n",
       "ridge2    0.010             111.358439                95.904135   \n",
       "ridge3    0.100             111.358439                95.904126   \n",
       "ridge4    1.000             111.358439                95.904035   \n",
       "ridge5   10.000             111.358440                95.903131   \n",
       "ridge6  100.000             111.358548                95.894268   \n",
       "lasso1    0.001             111.358439                95.903755   \n",
       "lasso2    0.010             111.358445                95.900332   \n",
       "lasso3    0.100             111.359051                95.866646   \n",
       "lasso4    1.000             111.419648                95.584678   \n",
       "lasso5   10.000             113.220780                95.048607   \n",
       "lasso6  100.000             152.346820               125.446062   \n",
       "\n",
       "        Training Accuracy R^2  Validation Accuracy R^2  \n",
       "ridge1               0.610823                 0.623414  \n",
       "ridge2               0.610823                 0.623414  \n",
       "ridge3               0.610823                 0.623415  \n",
       "ridge4               0.610823                 0.623415  \n",
       "ridge5               0.610823                 0.623418  \n",
       "ridge6               0.610823                 0.623453  \n",
       "lasso1               0.610823                 0.623416  \n",
       "lasso2               0.610823                 0.623429  \n",
       "lasso3               0.610821                 0.623562  \n",
       "lasso4               0.610609                 0.624669  \n",
       "lasso5               0.604314                 0.626774  \n",
       "lasso6               0.467576                 0.507413  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "alpha_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "row_names = ['ridge1', 'ridge2', 'ridge3', 'ridge4', 'ridge5', 'ridge6']\n",
    "i=0\n",
    "part5_results = pd.DataFrame(columns=['alpha', 'Training Accuracy MSE', 'Validation Accuracy MSE', 'Training Accuracy R^2', 'Validation Accuracy R^2'])\n",
    "for a in alpha_values:\n",
    "    ridge = Ridge(alpha=a).fit(X_train, y_train)\n",
    "    train_mse = mean_squared_error(y_train, ridge.predict(X_train))\n",
    "    train_r2 = r2_score(y_train, ridge.predict(X_train))\n",
    "    val_mse = mean_squared_error(y_val, ridge.predict(X_val))\n",
    "    val_r2 = r2_score(y_val, ridge.predict(X_val))\n",
    "    part5_results.loc[row_names[i]] = [a, train_mse, val_mse, train_r2, val_r2]\n",
    "    i +=1\n",
    "\n",
    "alpha_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "row_names = ['lasso1', 'lasso2', 'lasso3', 'lasso4', 'lasso5', 'lasso6']\n",
    "i=0\n",
    "from sklearn.linear_model import Lasso\n",
    "for a in alpha_values:\n",
    "    lasso = Lasso(alpha=a).fit(X_train, y_train)\n",
    "    train_mse = mean_squared_error(y_train, lasso.predict(X_train))\n",
    "    train_r2 = r2_score(y_train, lasso.predict(X_train))\n",
    "    val_mse = mean_squared_error(y_val, lasso.predict(X_val))\n",
    "    val_r2 = r2_score(y_val, lasso.predict(X_val))\n",
    "    part5_results.loc[row_names[i]] = [a, train_mse, val_mse, train_r2, val_r2]\n",
    "    i +=1\n",
    "\n",
    "part5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "The best r2 score came from any alpha used with the ridge method. This value is still not good enough though, as it is 0.610823, when it should be much closer to 1 to show a good fit of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
